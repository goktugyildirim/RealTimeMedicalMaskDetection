{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision \n",
    "import torch \n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "    \n",
    "    return model.eval()\n",
    "\n",
    "\n",
    "filepath = \"torch_classifier.pth\" #Pre-trained resnet50 ile fine-tunning yapılmış model, accuracy: %99 on the test set.\n",
    "model = load_checkpoint(filepath)\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    #transforms.Grayscale(num_output_channels=3), renkler önemli gray scale yapma\n",
    "    transforms.Resize((224,224)), # resnet girişi\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Time Detecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import cvlib as cv\n",
    "import sys\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "extra_pixel = 150\n",
    "\n",
    "#Parameters for Texts\n",
    "font_scala=0.6\n",
    "renk=(0,0,255)\n",
    "font_tip=cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "#Save Video\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('real-time-detecting.avi',fourcc, 20.0, (640,480))\n",
    "\n",
    "#Activate Capturing\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 800)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1000)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    #out.write(frame)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Detect Faces\n",
    "    faces, confidences = cv.detect_face(frame)\n",
    "    \n",
    "    \n",
    "    if(len(faces)!=0): #If the face is detected.\n",
    "        \n",
    "        #cv2.putText(frame,\"Face is detected.\",(25,40),font_tip,font_scala,renk)\n",
    "    \n",
    "        for face in faces:\n",
    "            (startX,startY) = face[0],face[1]\n",
    "            (endX,endY) = face[2],face[3]\n",
    "            current_face = frame[startX-extra_pixel:endX+extra_pixel,startY-extra_pixel:endY+extra_pixel]\n",
    "            \n",
    "            pil_image = Image.fromarray(current_face, mode = \"RGB\")#numpy to pil image because of torch model\n",
    "            pil_image = train_transforms(pil_image)\n",
    "            image = pil_image.unsqueeze(0)\n",
    "            \n",
    "    \n",
    "            result = model(image).data.numpy()\n",
    "            \n",
    "            #print(result)\n",
    "            \n",
    "            \n",
    "            if result[0][0] > result[0][1]:#masked\n",
    "                cv2.putText(frame,\"Masked\",(350,40),font_tip,font_scala,renk)\n",
    "                cv2.rectangle(frame, (startX,startY), (endX,endY), (0,255,0), 2)\n",
    "            else:#unmasked\n",
    "                cv2.putText(frame,\"Unmasked\",(350,40),font_tip,font_scala,renk)\n",
    "                cv2.rectangle(frame, (startX,startY), (endX,endY), (255,0,0), 2)\n",
    "            \n",
    "            out.write(frame)\n",
    "    \n",
    "    else: # If there is no face.    \n",
    "        cv2.rectangle(frame, (startX,startY), (endX,endY), (0,255,0), 2)\n",
    "        #cv2.putText(frame,\"There is no face.\",(25,40),font_tip,font_scala,renk)\n",
    "    \n",
    "    \n",
    "    cv2.imshow('Medical Mask Detector', frame)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting on the videos saved before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import cvlib as cv\n",
    "import sys\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Save Video\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('saved-video-before.avi',fourcc, 20.0, (450,1800))\n",
    "\n",
    "\n",
    "\n",
    "#Parameters for Texts\n",
    "font_scala=0.6\n",
    "renk=(0,0,255)\n",
    "font_tip=cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "cap = cv2.VideoCapture('output.avi')\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    pil_image = Image.fromarray(frame, mode = \"RGB\")#numpy to pil image because of torch model\n",
    "    pil_image = train_transforms(pil_image)\n",
    "    image = pil_image.unsqueeze(0)\n",
    "    \n",
    "    \n",
    "    #Detect Faces\n",
    "    faces, confidences = cv.detect_face(frame)\n",
    "    \n",
    "    if(len(faces)!=0): #If the face is detected.\n",
    "        \n",
    "        #cv2.putText(frame,\"Face is detected.\",(25,40),font_tip,font_scala,renk)\n",
    "    \n",
    "        for face in faces:\n",
    "            (startX,startY) = face[0],face[1]\n",
    "            (endX,endY) = face[2],face[3]\n",
    "            current_face = frame[startX:endX,startY:endY]\n",
    "            \n",
    "    \n",
    "            result = model(image).data.numpy()\n",
    "            \n",
    "            #print(result)\n",
    "            \n",
    "            \n",
    "            if result[0][0] > result[0][1]:#masked\n",
    "                cv2.putText(frame,\"Masked\",(350,40),font_tip,font_scala,renk)\n",
    "                cv2.rectangle(frame, (startX,startY), (endX,endY), (0,255,0), 2)\n",
    "            else:#unmasked\n",
    "                cv2.putText(frame,\"Unmasked\",(350,40),font_tip,font_scala,renk)\n",
    "                cv2.rectangle(frame, (startX,startY), (endX,endY), (255,0,0), 2)\n",
    "            \n",
    "            out.write(frame)\n",
    "    \n",
    "    else: # If there is no face.    \n",
    "        cv2.rectangle(frame, (startX,startY), (endX,endY), (0,255,0), 2)\n",
    "        #cv2.putText(frame,\"There is no face.\",(25,40),font_tip,font_scala,renk)\n",
    "    \n",
    "\n",
    "    cv2.imshow('Medical Mask Detector',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
